{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import neccesary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixing the csv file\n",
    "#You only need to run this code block ONCE when you first downloaded the source dataset.\n",
    "#Because (somehow) the original csv file is unusable, we need to do some formatting with simple read/write operations.\n",
    "srcfile = open('../datasets/USA_Housing.csv','r+')\n",
    "destfile = open('../datasets/USA_Housing_Fixed.csv','w')\n",
    "\n",
    "srclist = srcfile.readlines()\n",
    "for i in range(len(srclist)):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    if i % 2 != 0:\n",
    "        destfile.write(srclist[i].rpartition(\",\\\"\")[0] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.95454586e+04, 5.68286132e+00, 7.00918814e+00, 4.09000000e+00,\n",
       "        2.30868005e+04, 1.05903356e+06],\n",
       "       [7.92486425e+04, 6.00289981e+00, 6.73082102e+00, 3.09000000e+00,\n",
       "        4.01730722e+04, 1.50589091e+06],\n",
       "       [6.12870672e+04, 5.86588984e+00, 8.51272743e+00, 5.13000000e+00,\n",
       "        3.68821594e+04, 1.05898799e+06],\n",
       "       ...,\n",
       "       [6.37132729e+04, 4.78748780e+00, 8.01791445e+00, 3.12000000e+00,\n",
       "        4.25076117e+04, 1.03234687e+06],\n",
       "       [6.30791724e+04, 6.38116562e+00, 8.99598369e+00, 3.05000000e+00,\n",
       "        2.19407472e+04, 1.20111029e+06],\n",
       "       [7.52631156e+04, 3.60740473e+00, 7.96045754e+00, 5.36000000e+00,\n",
       "        3.08887505e+04, 1.18516086e+06]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = np.genfromtxt('../datasets/USA_Housing_Fixed.csv',delimiter=',',dtype='float64')\n",
    "dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split dataset to data and targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.95454586e+04, 5.68286132e+00, 7.00918814e+00, 4.09000000e+00,\n",
       "        2.30868005e+04],\n",
       "       [7.92486425e+04, 6.00289981e+00, 6.73082102e+00, 3.09000000e+00,\n",
       "        4.01730722e+04],\n",
       "       [6.12870672e+04, 5.86588984e+00, 8.51272743e+00, 5.13000000e+00,\n",
       "        3.68821594e+04],\n",
       "       ...,\n",
       "       [6.37132729e+04, 4.78748780e+00, 8.01791445e+00, 3.12000000e+00,\n",
       "        4.25076117e+04],\n",
       "       [6.30791724e+04, 6.38116562e+00, 8.99598369e+00, 3.05000000e+00,\n",
       "        2.19407472e+04],\n",
       "       [7.52631156e+04, 3.60740473e+00, 7.96045754e+00, 5.36000000e+00,\n",
       "        3.08887505e+04]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = dataset[:, 5]\n",
    "dataset = np.delete(dataset, 5, 1)\n",
    "dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we split the dataset into train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, dataset_test, targets_train, targets_test = train_test_split(dataset, targets, test_size=0.2, random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Creating the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our data values are increasingly large, we need to normalize it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.8615773e+04 5.9660344e+00 7.0001631e+00 3.9816835e+00 3.6168910e+04]]\n"
     ]
    }
   ],
   "source": [
    "#Layer to normalize training data\n",
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "\n",
    "#Adapt the normalizer to data\n",
    "normalizer.adapt(dataset_train)\n",
    "\n",
    "print(normalizer.mean.numpy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression with multiple inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = tf.keras.Sequential(\n",
    "    [normalizer,\n",
    "     tf.keras.layers.Dense(units=1)]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 62ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.2097762 ],\n",
       "       [ 0.27382514],\n",
       "       [ 1.7428455 ],\n",
       "       [-1.5083934 ],\n",
       "       [-1.2699938 ],\n",
       "       [ 0.12023443],\n",
       "       [-0.58222455],\n",
       "       [ 0.35414168],\n",
       "       [-0.9193488 ],\n",
       "       [ 0.61535835]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.predict(dataset_train[:10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you call a model, its weight matrices are built, you can check it through kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'dense_9/kernel:0' shape=(5, 1) dtype=float32, numpy=\n",
       "array([[-0.90284944],\n",
       "       [ 0.191041  ],\n",
       "       [-0.3287394 ],\n",
       "       [ 0.25876045],\n",
       "       [-0.5714843 ]], dtype=float32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.layers[1].kernel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model with <Model.compile> and train with <Model.fit> for 100 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "98/98 [==============================] - 1s 4ms/step - loss: 1233003.0000 - val_loss: 1233330.3750\n",
      "Epoch 2/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232992.8750 - val_loss: 1233320.5000\n",
      "Epoch 3/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232983.0000 - val_loss: 1233311.0000\n",
      "Epoch 4/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232973.2500 - val_loss: 1233301.1250\n",
      "Epoch 5/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232963.6250 - val_loss: 1233291.3750\n",
      "Epoch 6/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232953.8750 - val_loss: 1233281.7500\n",
      "Epoch 7/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232943.7500 - val_loss: 1233272.1250\n",
      "Epoch 8/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232934.1250 - val_loss: 1233262.3750\n",
      "Epoch 9/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232923.7500 - val_loss: 1233252.3750\n",
      "Epoch 10/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232914.5000 - val_loss: 1233242.6250\n",
      "Epoch 11/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232904.7500 - val_loss: 1233233.1250\n",
      "Epoch 12/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232894.5000 - val_loss: 1233223.3750\n",
      "Epoch 13/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232884.6250 - val_loss: 1233213.5000\n",
      "Epoch 14/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232875.0000 - val_loss: 1233203.6250\n",
      "Epoch 15/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232865.2500 - val_loss: 1233194.1250\n",
      "Epoch 16/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232855.3750 - val_loss: 1233184.1250\n",
      "Epoch 17/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232845.8750 - val_loss: 1233174.5000\n",
      "Epoch 18/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232836.3750 - val_loss: 1233164.7500\n",
      "Epoch 19/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232826.1250 - val_loss: 1233155.0000\n",
      "Epoch 20/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232816.3750 - val_loss: 1233145.2500\n",
      "Epoch 21/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232806.0000 - val_loss: 1233135.3750\n",
      "Epoch 22/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232796.7500 - val_loss: 1233125.7500\n",
      "Epoch 23/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232786.8750 - val_loss: 1233116.0000\n",
      "Epoch 24/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232776.8750 - val_loss: 1233106.1250\n",
      "Epoch 25/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232767.0000 - val_loss: 1233096.6250\n",
      "Epoch 26/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232757.1250 - val_loss: 1233086.7500\n",
      "Epoch 27/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232747.1250 - val_loss: 1233077.0000\n",
      "Epoch 28/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232737.6250 - val_loss: 1233067.2500\n",
      "Epoch 29/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232727.7500 - val_loss: 1233057.5000\n",
      "Epoch 30/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232718.3750 - val_loss: 1233047.6250\n",
      "Epoch 31/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232708.1250 - val_loss: 1233038.0000\n",
      "Epoch 32/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232698.5000 - val_loss: 1233028.3750\n",
      "Epoch 33/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232688.2500 - val_loss: 1233018.6250\n",
      "Epoch 34/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232678.8750 - val_loss: 1233008.7500\n",
      "Epoch 35/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232668.7500 - val_loss: 1232999.0000\n",
      "Epoch 36/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232659.3750 - val_loss: 1232989.3750\n",
      "Epoch 37/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232649.5000 - val_loss: 1232979.5000\n",
      "Epoch 38/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232639.7500 - val_loss: 1232969.8750\n",
      "Epoch 39/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232629.6250 - val_loss: 1232960.0000\n",
      "Epoch 40/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232620.0000 - val_loss: 1232950.3750\n",
      "Epoch 41/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232610.0000 - val_loss: 1232940.5000\n",
      "Epoch 42/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232600.1250 - val_loss: 1232930.7500\n",
      "Epoch 43/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232590.6250 - val_loss: 1232921.0000\n",
      "Epoch 44/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232580.6250 - val_loss: 1232911.1250\n",
      "Epoch 45/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232570.8750 - val_loss: 1232901.6250\n",
      "Epoch 46/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232561.1250 - val_loss: 1232891.8750\n",
      "Epoch 47/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232550.8750 - val_loss: 1232881.8750\n",
      "Epoch 48/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232541.2500 - val_loss: 1232872.1250\n",
      "Epoch 49/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232531.8750 - val_loss: 1232862.3750\n",
      "Epoch 50/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232522.0000 - val_loss: 1232852.5000\n",
      "Epoch 51/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232512.1250 - val_loss: 1232843.0000\n",
      "Epoch 52/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232502.3750 - val_loss: 1232833.5000\n",
      "Epoch 53/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232492.6250 - val_loss: 1232823.6250\n",
      "Epoch 54/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232482.5000 - val_loss: 1232813.7500\n",
      "Epoch 55/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232472.6250 - val_loss: 1232804.0000\n",
      "Epoch 56/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232462.8750 - val_loss: 1232794.2500\n",
      "Epoch 57/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232453.3750 - val_loss: 1232784.5000\n",
      "Epoch 58/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232443.3750 - val_loss: 1232774.8750\n",
      "Epoch 59/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232433.5000 - val_loss: 1232765.1250\n",
      "Epoch 60/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232423.6250 - val_loss: 1232755.5000\n",
      "Epoch 61/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232413.7500 - val_loss: 1232745.5000\n",
      "Epoch 62/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232403.8750 - val_loss: 1232735.7500\n",
      "Epoch 63/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232394.3750 - val_loss: 1232726.1250\n",
      "Epoch 64/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232384.3750 - val_loss: 1232716.2500\n",
      "Epoch 65/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232374.7500 - val_loss: 1232706.6250\n",
      "Epoch 66/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232364.8750 - val_loss: 1232697.0000\n",
      "Epoch 67/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232355.0000 - val_loss: 1232687.1250\n",
      "Epoch 68/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232345.6250 - val_loss: 1232677.3750\n",
      "Epoch 69/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232335.5000 - val_loss: 1232667.6250\n",
      "Epoch 70/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232325.7500 - val_loss: 1232657.8750\n",
      "Epoch 71/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232315.7500 - val_loss: 1232648.0000\n",
      "Epoch 72/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232306.0000 - val_loss: 1232638.5000\n",
      "Epoch 73/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232296.0000 - val_loss: 1232628.6250\n",
      "Epoch 74/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232286.1250 - val_loss: 1232618.8750\n",
      "Epoch 75/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232276.6250 - val_loss: 1232609.1250\n",
      "Epoch 76/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232266.6250 - val_loss: 1232599.5000\n",
      "Epoch 77/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232257.1250 - val_loss: 1232589.7500\n",
      "Epoch 78/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232246.8750 - val_loss: 1232579.7500\n",
      "Epoch 79/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232237.5000 - val_loss: 1232570.0000\n",
      "Epoch 80/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232227.6250 - val_loss: 1232560.2500\n",
      "Epoch 81/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232217.8750 - val_loss: 1232550.6250\n",
      "Epoch 82/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232207.8750 - val_loss: 1232540.7500\n",
      "Epoch 83/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232197.7500 - val_loss: 1232531.1250\n",
      "Epoch 84/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232188.2500 - val_loss: 1232521.3750\n",
      "Epoch 85/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232178.3750 - val_loss: 1232511.7500\n",
      "Epoch 86/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232168.6250 - val_loss: 1232502.1250\n",
      "Epoch 87/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232159.0000 - val_loss: 1232492.1250\n",
      "Epoch 88/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232149.2500 - val_loss: 1232482.3750\n",
      "Epoch 89/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232139.2500 - val_loss: 1232472.7500\n",
      "Epoch 90/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232129.5000 - val_loss: 1232463.0000\n",
      "Epoch 91/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232119.5000 - val_loss: 1232453.1250\n",
      "Epoch 92/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1232109.6250 - val_loss: 1232443.3750\n",
      "Epoch 93/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232099.7500 - val_loss: 1232433.7500\n",
      "Epoch 94/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232089.7500 - val_loss: 1232423.7500\n",
      "Epoch 95/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232080.2500 - val_loss: 1232414.0000\n",
      "Epoch 96/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232070.3750 - val_loss: 1232404.3750\n",
      "Epoch 97/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232060.8750 - val_loss: 1232394.7500\n",
      "Epoch 98/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232050.7500 - val_loss: 1232385.0000\n",
      "Epoch 99/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232041.2500 - val_loss: 1232375.1250\n",
      "Epoch 100/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232031.5000 - val_loss: 1232365.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24c1c329a10>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "    loss='mean_absolute_error'\n",
    ")\n",
    "\n",
    "linear_model.fit(\n",
    "    dataset_train,\n",
    "    targets_train,\n",
    "    epochs=100,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 1ms/step - loss: 1223946.2500\n"
     ]
    }
   ],
   "source": [
    "test_results = {}\n",
    "test_results['linear_model'] = linear_model.evaluate(dataset_test, targets_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression with a deep neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model = tf.keras.Sequential([\n",
    "    normalizer,\n",
    "    tf.keras.layers.Dense(128, activation=tf.keras.activations.elu),\n",
    "    tf.keras.layers.Dense(128, activation=tf.keras.activations.relu),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "dnn_model.compile(loss='mean_absolute_error',optimizer=tf.keras.optimizers.Adam(0.001))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "98/98 [==============================] - 1s 4ms/step - loss: 1232998.7500 - val_loss: 1233311.6250\n",
      "Epoch 2/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232891.3750 - val_loss: 1233070.6250\n",
      "Epoch 3/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1232363.5000 - val_loss: 1232167.0000\n",
      "Epoch 4/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1230834.5000 - val_loss: 1229931.3750\n",
      "Epoch 5/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1227716.2500 - val_loss: 1225961.3750\n",
      "Epoch 6/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1222752.1250 - val_loss: 1220051.0000\n",
      "Epoch 7/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1215674.3750 - val_loss: 1211909.8750\n",
      "Epoch 8/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1206230.2500 - val_loss: 1201280.6250\n",
      "Epoch 9/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1194186.2500 - val_loss: 1188005.2500\n",
      "Epoch 10/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1179325.6250 - val_loss: 1171786.1250\n",
      "Epoch 11/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1161423.5000 - val_loss: 1152511.6250\n",
      "Epoch 12/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1140322.8750 - val_loss: 1130017.5000\n",
      "Epoch 13/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1115837.6250 - val_loss: 1104076.7500\n",
      "Epoch 14/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1087809.3750 - val_loss: 1074570.5000\n",
      "Epoch 15/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1056149.3750 - val_loss: 1041402.7500\n",
      "Epoch 16/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 1020829.1250 - val_loss: 1004715.2500\n",
      "Epoch 17/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 981796.5625 - val_loss: 964651.5000\n",
      "Epoch 18/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 939137.5000 - val_loss: 920756.1250\n",
      "Epoch 19/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 892660.2500 - val_loss: 873102.7500\n",
      "Epoch 20/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 842405.3125 - val_loss: 821898.7500\n",
      "Epoch 21/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 789038.0625 - val_loss: 767650.8750\n",
      "Epoch 22/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 732613.6250 - val_loss: 710966.3125\n",
      "Epoch 23/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 673874.0625 - val_loss: 652361.6250\n",
      "Epoch 24/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 613564.1250 - val_loss: 592476.4375\n",
      "Epoch 25/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 552718.1250 - val_loss: 531847.0000\n",
      "Epoch 26/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 492036.2812 - val_loss: 471368.6562\n",
      "Epoch 27/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 433230.7500 - val_loss: 414113.4688\n",
      "Epoch 28/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 378309.5625 - val_loss: 360790.4375\n",
      "Epoch 29/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 329254.8125 - val_loss: 313943.1250\n",
      "Epoch 30/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 287548.0625 - val_loss: 273447.4375\n",
      "Epoch 31/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 251944.0625 - val_loss: 238391.2969\n",
      "Epoch 32/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 220398.5000 - val_loss: 206621.2344\n",
      "Epoch 33/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 191584.0938 - val_loss: 178902.4844\n",
      "Epoch 34/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 168052.2500 - val_loss: 157423.7969\n",
      "Epoch 35/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 150469.8594 - val_loss: 142051.3750\n",
      "Epoch 36/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 137179.6094 - val_loss: 131179.1250\n",
      "Epoch 37/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 127679.0234 - val_loss: 123282.4375\n",
      "Epoch 38/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 120663.4062 - val_loss: 117483.7812\n",
      "Epoch 39/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 115346.2969 - val_loss: 112918.3672\n",
      "Epoch 40/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 111047.6172 - val_loss: 109311.1797\n",
      "Epoch 41/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 107456.3594 - val_loss: 106250.8750\n",
      "Epoch 42/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 104599.2500 - val_loss: 103785.4844\n",
      "Epoch 43/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 102319.7969 - val_loss: 101718.0312\n",
      "Epoch 44/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 100462.0781 - val_loss: 100236.9766\n",
      "Epoch 45/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 98931.8828 - val_loss: 98818.3359\n",
      "Epoch 46/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 97674.0625 - val_loss: 97523.6641\n",
      "Epoch 47/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 96652.5625 - val_loss: 96578.6172\n",
      "Epoch 48/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 95816.4453 - val_loss: 95877.0234\n",
      "Epoch 49/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 95085.4688 - val_loss: 95136.4219\n",
      "Epoch 50/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 94512.0547 - val_loss: 94609.6328\n",
      "Epoch 51/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 94017.0078 - val_loss: 94098.3672\n",
      "Epoch 52/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 93548.0000 - val_loss: 93644.9844\n",
      "Epoch 53/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 93137.6562 - val_loss: 93255.0156\n",
      "Epoch 54/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 92705.4766 - val_loss: 92913.4766\n",
      "Epoch 55/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 92372.3984 - val_loss: 92547.3828\n",
      "Epoch 56/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 92042.2188 - val_loss: 92421.6406\n",
      "Epoch 57/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 91737.9531 - val_loss: 92076.0625\n",
      "Epoch 58/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 91424.4531 - val_loss: 91778.4609\n",
      "Epoch 59/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 91124.7188 - val_loss: 91526.9766\n",
      "Epoch 60/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 90830.6172 - val_loss: 91308.6328\n",
      "Epoch 61/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 90561.3359 - val_loss: 91082.1250\n",
      "Epoch 62/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 90336.9688 - val_loss: 90859.9766\n",
      "Epoch 63/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 90084.0156 - val_loss: 90658.9453\n",
      "Epoch 64/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 89871.0078 - val_loss: 90465.8984\n",
      "Epoch 65/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 89623.8047 - val_loss: 90215.8672\n",
      "Epoch 66/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 89430.2031 - val_loss: 90128.8281\n",
      "Epoch 67/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 89193.3516 - val_loss: 89757.4453\n",
      "Epoch 68/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 89005.5000 - val_loss: 89631.6484\n",
      "Epoch 69/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 88734.5703 - val_loss: 89451.7266\n",
      "Epoch 70/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 88584.0469 - val_loss: 89283.1875\n",
      "Epoch 71/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 88360.6172 - val_loss: 89229.3750\n",
      "Epoch 72/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 88237.2344 - val_loss: 88949.8750\n",
      "Epoch 73/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 88029.8438 - val_loss: 88751.3359\n",
      "Epoch 74/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 87896.5859 - val_loss: 88578.1328\n",
      "Epoch 75/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 87685.0547 - val_loss: 88480.3203\n",
      "Epoch 76/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 87499.6250 - val_loss: 88348.7812\n",
      "Epoch 77/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 87365.3672 - val_loss: 88274.3359\n",
      "Epoch 78/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 87198.2266 - val_loss: 88126.7266\n",
      "Epoch 79/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 87046.8984 - val_loss: 88069.5469\n",
      "Epoch 80/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 86857.3828 - val_loss: 87931.3516\n",
      "Epoch 81/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 86734.3047 - val_loss: 87740.0859\n",
      "Epoch 82/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 86598.7266 - val_loss: 87742.3906\n",
      "Epoch 83/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 86490.3359 - val_loss: 87554.3594\n",
      "Epoch 84/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 86327.4688 - val_loss: 87521.1719\n",
      "Epoch 85/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 86235.4844 - val_loss: 87457.3672\n",
      "Epoch 86/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 86103.4922 - val_loss: 87403.8906\n",
      "Epoch 87/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 85954.0703 - val_loss: 87217.8750\n",
      "Epoch 88/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 85875.0000 - val_loss: 87181.6797\n",
      "Epoch 89/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 85711.1797 - val_loss: 87028.8125\n",
      "Epoch 90/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 85629.2109 - val_loss: 87004.0547\n",
      "Epoch 91/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 85504.6953 - val_loss: 86866.2344\n",
      "Epoch 92/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 85425.5625 - val_loss: 86868.2969\n",
      "Epoch 93/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 85382.4609 - val_loss: 86741.9453\n",
      "Epoch 94/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 85256.9531 - val_loss: 86638.3359\n",
      "Epoch 95/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 85154.8984 - val_loss: 86652.0391\n",
      "Epoch 96/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 85091.3516 - val_loss: 86520.8281\n",
      "Epoch 97/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 85012.4844 - val_loss: 86573.0703\n",
      "Epoch 98/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 84902.9141 - val_loss: 86448.7969\n",
      "Epoch 99/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 84853.2266 - val_loss: 86313.3047\n",
      "Epoch 100/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 84746.6328 - val_loss: 86224.9219\n"
     ]
    }
   ],
   "source": [
    "errors = dnn_model.fit(dataset_train, targets_train, validation_split=0.2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 2ms/step - loss: 83469.1953\n"
     ]
    }
   ],
   "source": [
    "test_results['dnn_model'] = dnn_model.evaluate(dataset_test, targets_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean absolute error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>linear_model</th>\n",
       "      <td>1.223946e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dnn_model</th>\n",
       "      <td>8.346920e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Mean absolute error \n",
       "linear_model          1.223946e+06\n",
       "dnn_model             8.346920e+04"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(test_results, index=['Mean absolute error ']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-4.27180469e+04,  5.09120141e+04,  6.54148266e+04,  1.27115890e+05,\n",
       "        2.39850217e+05,  8.58556551e+04, -1.52335699e+05,  8.28027108e+04,\n",
       "       -9.22203601e+04,  3.29590995e+04,  1.18392783e+04,  9.21501395e+04,\n",
       "        4.74883328e+03, -5.79757988e+04,  1.78821023e+05,  1.46221593e+04,\n",
       "       -9.71651379e+04, -1.31417193e+05, -1.24705634e+04,  2.19014963e+05,\n",
       "       -1.03927794e+05, -2.56763848e+05,  1.18968884e+05,  1.84988501e+05,\n",
       "       -1.19523030e+04, -1.17463119e+05,  7.81239411e+04, -1.37696188e+05,\n",
       "       -1.90663459e+05, -1.22979489e+05,  2.65419178e+04, -1.76145439e+05,\n",
       "        1.48128882e+05,  4.02035763e+04, -8.97690755e+04,  1.35754173e+04,\n",
       "       -4.70758303e+04, -1.71257474e+04,  3.32482181e+04,  1.45042317e+04,\n",
       "       -3.18648876e+04, -9.08736031e+04,  8.44530665e+04, -4.38490838e+04,\n",
       "        4.77438963e+04, -1.21078219e+05,  7.62003537e+04, -1.74295882e+05,\n",
       "        9.10034292e+04,  1.22640021e+05,  2.12493611e+04,  3.74498102e+05,\n",
       "       -6.22182199e+04,  2.33095273e+04, -3.80811314e+05,  5.11735953e+04,\n",
       "        2.38920451e+04,  4.72467205e+04, -1.51033174e+04,  9.87029416e+04,\n",
       "        1.54190620e+05,  1.47547764e+05, -9.52248754e+04, -9.45437503e+04,\n",
       "       -4.22582070e+04,  2.39092400e+05, -4.75354520e+04, -3.04384942e+05,\n",
       "       -5.87098011e+04, -1.90563579e+05, -1.04329670e+05,  2.02543189e+04,\n",
       "       -5.19079129e+04, -7.03152948e+04,  3.11768252e+05,  1.58851869e+05,\n",
       "       -3.44871444e+04,  4.24311441e+04, -4.26022266e+04,  5.55733985e+04,\n",
       "       -6.54018458e+04,  1.00027221e+04,  1.12525789e+05,  4.39248453e+04,\n",
       "       -3.33362230e+04, -4.18233825e+04,  3.42284554e+04, -3.69432514e+03,\n",
       "       -4.83364593e+04,  3.63766763e+04,  1.53977047e+05, -5.96726056e+04,\n",
       "       -1.34962957e+05, -1.15279903e+05,  1.04385492e+05,  9.59393609e+04,\n",
       "        1.34649602e+05, -2.04139357e+05,  1.29551384e+05,  5.88785987e+04,\n",
       "        3.18113455e+04, -3.87885151e+04, -2.58483205e+04, -5.75596081e+04,\n",
       "        8.35095443e+04, -9.38163795e+04, -1.72589364e+05, -1.06983580e+05,\n",
       "       -1.08541399e+05,  2.05092516e+05,  1.39370104e+05,  8.64302052e+04,\n",
       "        6.20530283e+03,  1.35106934e+05, -1.14912675e+04, -1.53764785e+05,\n",
       "       -1.34277619e+04,  3.44047545e+04,  1.39197426e+04,  4.82173838e+04,\n",
       "       -6.97692237e+04, -7.12142226e+04, -2.50229408e+04, -4.39492783e+04,\n",
       "       -1.30826871e+05,  8.81718766e+03,  1.83250663e+05, -3.64138372e+04,\n",
       "        1.14014055e+05, -9.30672688e+04, -1.08280467e+05,  6.10264704e+04,\n",
       "        7.21073739e+04,  1.22646514e+05, -1.11444283e+05, -5.56908826e+04,\n",
       "       -2.36684803e+04, -4.22997074e+04, -8.90316603e+04,  7.16704928e+04,\n",
       "        5.13819110e+04, -2.42534887e+04, -1.70352312e+05,  2.51070530e+05,\n",
       "       -5.92839732e+04,  2.10978627e+05, -1.59466975e+05,  3.06526371e+04,\n",
       "       -1.81397922e+05, -1.18516303e+05,  3.64413394e+04, -9.29920797e+04,\n",
       "       -1.60399263e+05,  5.80649079e+04, -2.10094760e+05,  2.52000948e+05,\n",
       "        3.12541200e+04, -3.26591651e+04, -1.87900162e+04, -1.87642957e+04,\n",
       "       -8.26224786e+04, -1.03531157e+04,  4.25088717e+05,  2.16766228e+05,\n",
       "        1.11330242e+05, -1.05126851e+05, -1.07073292e+05, -4.03061259e+03,\n",
       "       -5.06367266e+04,  1.47151110e+05, -4.38954133e+04, -2.98816567e+04,\n",
       "        6.81477197e+04, -7.12233593e+04, -1.10054596e+04,  1.02355294e+05,\n",
       "        4.04515889e+04, -4.68460005e+04, -7.51286634e+04,  1.02799271e+05,\n",
       "       -1.46328117e+03,  1.39089806e+05, -2.04834884e+04, -6.98027542e+03,\n",
       "       -2.07768358e+05, -8.01930399e+04, -7.02126831e+04,  8.28777527e+04,\n",
       "       -9.67816634e+04, -1.22595051e+05, -5.98376014e+04,  1.80943668e+05,\n",
       "        1.78105304e+05, -1.09996440e+05,  5.60020824e+04,  5.39845909e+04,\n",
       "        7.86655998e+04,  7.07386603e+04,  5.68224494e+04,  6.73610728e+04,\n",
       "        2.88371419e+04, -7.89101761e+04,  1.64697487e+04,  3.79765435e+04,\n",
       "        8.91443699e+04,  3.37873485e+04,  1.59913862e+05, -9.58210585e+03,\n",
       "        3.01478035e+05, -1.43013525e+04,  4.06360505e+04, -2.76664468e+05,\n",
       "        1.01862188e+05, -9.61044971e+04, -3.07353962e+04, -5.13401447e+04,\n",
       "        4.36070552e+04,  5.89113638e+04, -1.14354749e+03, -2.93013794e+04,\n",
       "        1.74227250e+02,  2.35103631e+04, -1.57112832e+05, -3.60541850e+04,\n",
       "        6.97890939e+04, -7.48657650e+04, -1.22160547e+04, -6.56841750e+04,\n",
       "       -3.44244821e+04,  3.02964449e+04,  1.83695522e+05, -6.74072624e+04,\n",
       "        8.22408368e+04, -3.61189223e+04, -1.35180542e+05,  9.77725271e+03,\n",
       "        6.57021286e+04,  1.45189487e+05, -1.09589608e+05, -1.22143075e+05,\n",
       "       -7.25261578e+04,  1.63848773e+04, -5.81814291e+04, -1.23115255e+05,\n",
       "       -6.92513489e+04, -1.44159986e+05,  1.82085631e+05,  6.27200047e+04,\n",
       "       -1.28531563e+05, -1.87168318e+04,  6.54172533e+04,  2.19349843e+04,\n",
       "       -7.54598220e+04, -1.95906275e+04,  1.76833776e+03, -2.17478521e+05,\n",
       "        6.94106184e+04, -1.10142645e+05, -1.87239963e+05,  1.87510174e+05,\n",
       "        6.83249306e+04, -1.84992090e+04, -1.60758588e+04, -4.10830097e+04,\n",
       "       -7.42507881e+04,  3.96799796e+04,  1.64981803e+05, -5.77691781e+04,\n",
       "       -7.56967144e+04,  5.37110785e+04,  1.11112798e+05, -3.00510145e+04,\n",
       "       -1.00374990e+05,  2.23146928e+04,  7.59868380e+04,  1.35637482e+05,\n",
       "       -1.07234273e+05, -3.07164240e+02, -1.90810480e+05, -1.57842309e+05,\n",
       "        1.00532791e+05,  1.86480830e+04, -2.41374345e+05, -3.24636431e+04,\n",
       "        4.51405855e+04,  6.85622457e+04, -1.78827153e+04,  4.69467661e+04,\n",
       "        3.34148563e+04, -1.98167629e+04, -5.00202500e+04,  2.64449099e+04,\n",
       "       -8.36132134e+04, -1.05608348e+05,  3.21424793e+04, -7.17708702e+03,\n",
       "       -7.91479021e+03,  6.94149298e+04, -1.05374496e+05,  1.29731641e+05,\n",
       "        1.09821998e+05, -7.37834728e+04, -4.88556777e+04, -2.77742174e+04,\n",
       "       -1.18869264e+04, -9.52939168e+04,  2.44504306e+04,  1.45378472e+05,\n",
       "        9.38985643e+04, -1.82864835e+05,  5.75076803e+04,  1.55600714e+05,\n",
       "       -3.85287351e+04,  1.34270416e+05,  1.93416646e+04,  5.34892605e+04,\n",
       "       -7.57441317e+04,  5.60580088e+04,  1.72556566e+05,  1.88687531e+05,\n",
       "       -5.94607116e+04,  1.57880720e+05, -7.31321159e+04,  1.88284692e+04,\n",
       "        5.13831960e+04, -1.41918964e+05, -9.87389388e+03, -2.66503811e+05,\n",
       "       -7.45023666e+04,  6.24733413e+04,  1.34657113e+05,  8.54963173e+03,\n",
       "        1.24747957e+05, -1.69676380e+05,  1.99276198e+05,  9.71848764e+04,\n",
       "        6.54436031e+04,  1.80323302e+05,  2.03486979e+05,  1.39486158e+05,\n",
       "        2.22842511e+05, -9.61842354e+04,  6.85367033e+04,  1.99858363e+05,\n",
       "        3.17645069e+04, -3.88275951e+04,  7.49516856e+04, -8.43381002e+04,\n",
       "        1.10011891e+05,  1.42461458e+04, -8.55672483e+04, -3.82275947e+03,\n",
       "       -2.21941010e+04,  1.73359479e+03,  2.21856639e+05, -6.95346015e+04,\n",
       "       -2.12509777e+04, -3.35820861e+04,  2.78868385e+05,  2.82910094e+04,\n",
       "        1.08644606e+05,  8.62927172e+04, -5.27942004e+04,  1.21546290e+05,\n",
       "       -8.57579567e+04,  9.26098916e+03, -2.78565661e+03, -1.60347613e+04,\n",
       "       -1.43701928e+05, -3.28299567e+04, -5.11842559e+04, -8.39550915e+03,\n",
       "        7.33436813e+04, -1.30984288e+05,  2.03527296e+04, -2.38488232e+04,\n",
       "       -4.04908888e+04,  5.64027217e+03, -2.61244791e+04, -1.73990215e+05,\n",
       "       -1.71801633e+05,  8.62028528e+03,  1.50813514e+05,  1.63415875e+05,\n",
       "        6.82763802e+04,  1.16247967e+04,  1.08399844e+05,  4.22549595e+04,\n",
       "        2.39462631e+04,  1.16902029e+05,  8.92112911e+04,  1.50341156e+05,\n",
       "       -8.36086179e+04,  4.83821533e+04,  1.88360592e+04, -7.54882719e+04,\n",
       "        2.48649154e+04, -3.50895069e+04, -1.08522407e+05, -1.96620366e+05,\n",
       "        1.54494020e+05,  5.15532131e+04,  1.26468890e+04,  7.81572821e+04,\n",
       "        1.97773932e+05, -1.68406051e+04, -1.05820395e+03, -8.96508372e+04,\n",
       "       -8.20540309e+04,  7.17963666e+03,  8.28982574e+04,  1.67379865e+05,\n",
       "       -2.41656131e+05,  1.74416995e+05, -4.00653493e+04,  4.82156079e+04,\n",
       "        5.90490719e+04, -2.84806665e+04,  7.25758401e+04,  1.92195289e+05,\n",
       "        8.35584827e+03, -4.07815785e+04,  4.25106449e+04,  6.60031987e+04,\n",
       "        1.92010301e+05,  7.08200899e+04,  4.36460393e+04, -2.46431981e+05,\n",
       "       -6.26512622e+04, -2.70151940e+05,  1.42508542e+04,  3.78146882e+04,\n",
       "       -1.56805957e+05,  7.19464857e+04,  6.40352145e+04,  5.50216191e+04,\n",
       "       -6.77355665e+04,  4.19551672e+01,  1.97873384e+05, -6.71025413e+04,\n",
       "        5.17531657e+04,  2.88590648e+04, -3.28789678e+03, -8.24061471e+03,\n",
       "       -6.35663811e+04, -1.11143940e+05,  3.54258037e+04, -7.42109741e+04,\n",
       "       -2.73810228e+03, -3.59061914e+04,  3.31296737e+05,  8.45466148e+04,\n",
       "       -8.48432664e+04,  1.30771927e+05,  1.17625603e+03, -8.07074396e+04,\n",
       "        2.10656347e+05,  4.61299482e+04,  1.44632852e+05,  4.66799562e+04,\n",
       "        2.40313842e+04,  7.81102384e+04, -7.74004518e+04,  5.24611166e+04,\n",
       "       -9.16443504e+04, -7.78343242e+04,  6.40231650e+04, -4.07964375e+04,\n",
       "       -1.22784267e+05,  3.10811757e+04,  2.00448984e+04,  1.58149978e+05,\n",
       "       -1.74936455e+04, -4.03232767e+04,  1.51777352e+03, -7.59592208e+04,\n",
       "       -3.11720712e+04, -2.99650444e+04,  1.99039530e+05,  4.21406277e+04,\n",
       "        8.59042368e+04,  7.88153426e+04, -6.77624596e+04,  6.58492132e+04,\n",
       "        7.44212192e+04, -1.32183004e+05, -1.06372617e+05,  1.85962259e+05,\n",
       "        2.99145665e+04,  7.39382924e+04,  1.14212980e+05,  4.27321267e+04,\n",
       "        4.33318540e+04, -1.14243126e+05,  4.28176189e+04, -7.46251557e+04,\n",
       "       -2.14551938e+04,  7.38243745e+04,  1.72051802e+04, -5.81615012e+04,\n",
       "       -4.76231107e+04,  3.00931320e+04,  2.71469274e+05, -1.57668552e+05,\n",
       "        1.99241642e+04,  3.99420311e+04, -2.53909314e+04,  4.32734045e+04,\n",
       "        8.49338120e+03,  3.54458700e+04,  9.04322487e+04,  2.30815617e+05,\n",
       "        1.15372457e+04, -4.88492111e+04, -1.07670056e+05, -4.90917193e+04,\n",
       "        3.69360708e+03,  4.41144746e+03, -1.79565511e+04, -7.80128708e+04,\n",
       "        9.76161854e+04, -6.36871062e+04, -1.27629096e+04, -5.05432794e+04,\n",
       "        1.86428037e+05, -9.59733786e+04, -8.20096964e+04,  7.08076533e+04,\n",
       "       -1.30530283e+05, -5.28765704e+02, -9.82698827e+03, -4.53566645e+04,\n",
       "        2.76439240e+04,  2.04042224e+05, -3.20019336e+03,  4.87625804e+04,\n",
       "       -1.76394041e+05,  1.61523599e+03,  9.13860709e+04, -1.66855067e+05,\n",
       "       -1.53659942e+05,  4.61913915e+04,  5.69098900e+04,  1.58791459e+05,\n",
       "        3.96525603e+03,  4.41965827e+04, -4.33711588e+04, -2.99126218e+05,\n",
       "       -1.21544822e+05,  5.42859988e+04, -9.88439164e+04,  7.71862791e+02,\n",
       "        2.05937405e+05,  2.29498215e+04, -1.52211622e+04,  4.76712223e+04,\n",
       "       -1.01481690e+05, -1.28569518e+05,  4.10664622e+04,  1.33937093e+05,\n",
       "        1.02094597e+05,  4.68328478e+04, -7.38518456e+04,  8.23952775e+04,\n",
       "        5.99945643e+04, -3.49994726e+04,  1.49173276e+04,  1.19150018e+05,\n",
       "        1.00933563e+05, -5.23234647e+04,  1.73943752e+05,  8.13104827e+03,\n",
       "        6.59918263e+04,  4.93278334e+04, -9.65029542e+04, -5.26577720e+04,\n",
       "       -1.18469499e+05, -3.97131947e+04,  1.73016939e+04, -5.65665045e+04,\n",
       "        2.27688759e+05,  7.57947302e+04, -1.56673721e+04, -1.06046055e+05,\n",
       "       -5.01709379e+04, -2.88582417e+04,  1.11703607e+05,  1.70861578e+05,\n",
       "        2.52579049e+05,  6.64046065e+04,  1.46453229e+05, -6.75206170e+04,\n",
       "        3.48575527e+04,  8.54955064e+04,  3.43507468e+04,  2.74372232e+05,\n",
       "       -2.70950177e+05,  1.57443201e+05, -5.47884852e+03, -6.16653564e+04,\n",
       "       -1.87816242e+05, -1.33057909e+05,  8.91990920e+04, -6.94619286e+04,\n",
       "        7.63930890e+04,  2.07130442e+04, -2.07928416e+05, -1.56271306e+05,\n",
       "        7.52186206e+03,  1.46498047e+05, -1.23781711e+05, -5.76437370e+03,\n",
       "        6.81564224e+04, -9.33919609e+04,  9.15849160e+04, -2.98045855e+05,\n",
       "       -5.76233454e+04, -6.65972952e+04, -2.39244287e+05, -1.08727309e+05,\n",
       "        1.10821213e+04, -5.59059131e+02, -2.46101442e+05, -1.55495368e+04,\n",
       "       -5.04294303e+04,  6.28145992e+04, -1.21988093e+05,  1.32695988e+05,\n",
       "       -2.06214901e+04,  7.38359330e+04,  8.38282607e+04, -2.42408896e+04,\n",
       "        1.23936021e+05, -1.31683415e+05,  1.32252414e+05,  8.60417437e+04,\n",
       "        6.43799092e+04,  4.87634948e+04, -3.50234626e+04, -5.89925357e+04,\n",
       "        2.06973522e+04, -1.07494526e+05,  3.05163524e+04,  2.03818650e+05,\n",
       "       -3.18864993e+04,  1.92830012e+04,  1.67428446e+05,  3.33275342e+05,\n",
       "       -2.82429109e+04, -3.11993131e+05, -1.20395142e+05, -7.44945080e+04,\n",
       "        3.09219895e+04, -1.54037523e+05, -2.72452992e+04, -2.24967208e+05,\n",
       "        3.58614852e+04, -7.99902470e+04,  6.62450453e+04,  2.08443359e+04,\n",
       "       -1.16135662e+05,  1.18709011e+05, -4.89533432e+04, -1.20284701e+05,\n",
       "       -5.05401620e+04,  1.09875127e+05, -9.46657447e+03,  3.18615924e+04,\n",
       "        7.42222557e+04,  6.21662714e+04, -4.86216051e+04, -1.11143862e+05,\n",
       "       -1.21788767e+05,  9.40759555e+04,  2.19346903e+05,  9.47605846e+04,\n",
       "       -8.38020277e+04, -6.47892476e+04,  3.94182295e+04,  5.09563871e+03,\n",
       "        6.05305480e+04, -2.10792443e+05, -5.60293759e+04,  2.44675352e+05,\n",
       "        1.72910141e+04,  5.65067173e+04,  9.15416314e+03, -2.34463639e+04,\n",
       "        2.49546757e+05,  1.18364226e+03,  6.97141816e+03, -6.21964485e+04,\n",
       "        1.42421302e+05, -1.53873793e+05,  7.16883812e+04, -2.05337492e+04,\n",
       "        8.38089601e+04,  1.55139254e+04,  5.02103678e+04,  1.02452924e+05,\n",
       "        1.64713189e+05, -4.29404659e+04, -8.53240436e+04, -3.90212191e+04,\n",
       "       -3.17609975e+04,  6.17158703e+04, -4.80626613e+04,  2.72582538e+04,\n",
       "       -1.43870353e+05,  1.62653891e+05,  9.94603269e+04, -1.11135525e+04,\n",
       "        3.75559545e+05, -4.32344082e+04, -1.34203305e+04,  6.49903240e+04,\n",
       "        6.27274686e+04,  2.23212813e+04,  1.22348012e+05, -9.18505292e+03,\n",
       "        1.65077778e+05, -1.13536756e+04, -6.07646969e+04, -1.20585796e+05,\n",
       "       -9.23919207e+04, -1.50614169e+05,  8.86398732e+04,  9.26157784e+04,\n",
       "       -1.08090792e+03,  3.79655103e+04, -5.68659521e+03,  2.83099689e+04,\n",
       "       -2.17567773e+05, -1.25663921e+05, -1.20988657e+05, -2.03690686e+04,\n",
       "       -1.65442002e+05, -4.59231450e+04, -8.06775503e+04,  1.63800945e+04,\n",
       "       -5.05179144e+04,  1.22655558e+05, -1.68066252e+05, -1.06028754e+05,\n",
       "        2.12529951e+05, -1.56940992e+04, -3.80569612e+04,  4.33211559e+04,\n",
       "       -3.99440895e+04, -5.12427912e+04,  2.46068159e+02, -8.08897764e+04,\n",
       "       -1.06999207e+05,  1.46435583e+05, -1.11452148e+05,  4.49568988e+04,\n",
       "       -3.52146431e+04,  3.90715063e+05,  4.14544346e+04, -7.96099999e+04,\n",
       "        5.07628332e+04, -3.63349964e+03,  6.38985947e+04,  1.65812404e+05,\n",
       "        9.81620415e+04,  5.40835967e+04,  1.36573276e+05, -2.13696151e+04,\n",
       "        1.34259535e+05, -4.53439741e+04, -2.87145234e+04,  2.43639575e+05,\n",
       "        5.43838774e+04,  1.74000696e+04,  7.72764536e+04,  1.56809404e+05,\n",
       "        7.25943359e+04,  4.63739696e+04, -9.82513341e+03, -7.95870123e+03,\n",
       "        1.45575455e+05,  1.00712514e+05,  1.06447935e+05,  1.19729411e+04,\n",
       "       -5.12414823e+04, -1.31996972e+04, -2.01393373e+04,  7.81206791e+04,\n",
       "        8.65758321e+04, -8.98094156e+04, -3.16170974e+04, -4.64724529e+04,\n",
       "       -2.07390824e+05,  1.42657447e+05,  5.25946420e+04,  2.94029513e+04,\n",
       "        1.26085540e+05,  1.55318886e+05, -9.71406323e+04,  6.32888026e+03,\n",
       "       -9.49812560e+04, -1.09763272e+03, -1.63157007e+05,  3.02696243e+03,\n",
       "        1.18768866e+04,  2.97599188e+04,  8.35824776e+03,  2.09546856e+04,\n",
       "        1.13131982e+05,  2.69356838e+04,  7.92322879e+04,  1.29969622e+05,\n",
       "        9.33312571e+04, -1.06250399e+05, -1.29293795e+05, -2.34641569e+05,\n",
       "       -8.46842091e+04, -7.16054812e+03,  6.68700828e+04,  1.34114604e+05,\n",
       "        1.37737127e+04,  1.50841985e+05,  2.03006335e+05, -1.58788270e+04,\n",
       "        8.78087232e+04,  2.50104517e+05, -2.30010378e+03, -1.04613020e+05,\n",
       "        1.08020443e+05, -6.65223617e+04,  5.05400555e+04,  1.40481040e+05,\n",
       "        2.27358172e+04,  1.13711958e+05, -3.78388126e+04, -1.25260754e+05,\n",
       "       -5.89761183e+04, -4.88117177e+04,  1.25506884e+05,  8.80673222e+04,\n",
       "       -1.00759950e+04, -1.03776099e+05, -1.24139581e+05,  1.59513024e+03,\n",
       "       -4.91958780e+04, -2.50183224e+05,  8.33837401e+04, -1.12155107e+04,\n",
       "        3.70364617e+05, -1.09843105e+05, -2.21647167e+04, -1.45993134e+04,\n",
       "       -8.89592279e+04,  7.24200469e+02, -8.08475550e+04,  2.15322791e+04,\n",
       "       -1.09105145e+03, -7.80246403e+04,  4.86689350e+03, -7.37797834e+03,\n",
       "        3.59658142e+04,  1.42090741e+05,  1.81009307e+05,  1.30649311e+03,\n",
       "        2.75687234e+04,  5.87980492e+04, -2.61815997e+04, -1.27292429e+05,\n",
       "       -1.20593459e+04, -4.73734277e+03, -6.93366173e+04,  1.13880312e+05,\n",
       "        1.74306718e+05, -4.43623837e+04,  3.95123937e+04, -7.63772878e+04,\n",
       "        1.26880910e+05,  1.37175169e+05,  9.79488491e+04, -6.54034352e+03,\n",
       "        1.61175032e+04,  2.89594131e+05, -8.26731742e+04,  3.16098049e+04,\n",
       "        1.25896925e+05,  1.00311312e+05, -1.03154707e+05,  7.10496480e+04,\n",
       "        6.14110234e+04, -5.29248000e+04, -2.41457322e+05, -2.00268362e+04,\n",
       "        1.39343327e+05, -6.72316710e+04,  9.96794377e+03,  6.80525182e+04,\n",
       "       -2.29487062e+05, -1.56085869e+04,  1.29418698e+05,  2.64766076e+04,\n",
       "       -6.76199235e+04,  7.79758368e+04,  1.10244866e+05, -1.61608215e+05,\n",
       "        1.25222739e+04, -6.59627411e+04,  5.41536189e+04, -4.98340811e+04,\n",
       "       -6.42654836e+04, -2.04313040e+03, -7.45740507e+03,  1.23355374e+05,\n",
       "        1.91102487e+05, -1.81645988e+05, -9.07892969e+04, -1.26100333e+05,\n",
       "        5.77875496e+04,  5.82618275e+04, -9.73026236e+04, -2.30207114e+05,\n",
       "       -1.41075266e+05,  9.08175199e+04,  1.05262802e+05,  2.48574065e+04,\n",
       "        8.41838129e+04,  1.33502710e+05,  4.63386933e+04,  1.49863457e+05,\n",
       "       -5.56598865e+04,  1.20317198e+05,  1.03015650e+05,  1.73411030e+05,\n",
       "        1.32615023e+04,  1.50026563e+05,  1.03948294e+05, -1.61757957e+05,\n",
       "       -1.81284579e+05,  2.18228420e+05, -1.12283834e+05, -3.10458577e+04,\n",
       "        9.21303050e+04, -1.87018631e+05,  3.41358760e+05, -9.31164598e+04,\n",
       "       -6.80805538e+04,  1.29276838e+05, -3.80075599e+04, -4.69525807e+03,\n",
       "       -1.00006019e+04, -9.21005143e+04,  1.47742161e+05,  3.89536991e+04,\n",
       "        2.15170640e+05, -4.40537293e+04, -1.48192785e+05, -1.80214377e+05,\n",
       "        1.40681579e+04,  8.44511439e+04, -1.07767846e+05,  6.31555908e+04,\n",
       "        1.55757097e+05, -6.71399921e+03, -4.30127249e+04,  1.87274680e+05,\n",
       "        1.53110619e+04, -5.75428764e+04, -9.92762919e+04,  3.78126077e+04,\n",
       "        1.74437924e+05, -7.31422744e+04,  2.16851174e+05, -9.06496101e+04,\n",
       "        1.66324548e+05,  7.85883918e+04, -1.48066679e+03])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = dnn_model.predict(dataset_test)\n",
    "\n",
    "test_predictions.flatten() - targets_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
