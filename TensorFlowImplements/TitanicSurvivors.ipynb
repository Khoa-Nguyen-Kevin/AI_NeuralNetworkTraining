{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network AI - Titanic Survivors prediction - Classification problem."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credit to dataset: ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import neccessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sklearn as sk\n",
    "import keras.layers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create train and test dataframes (for plotting)\n",
    "test_dataframe = pd.read_csv('..\\datasets\\Titanic_Survivors\\\\test.csv',quotechar='\"')\n",
    "train_dataframe = pd.read_csv('..\\datasets\\Titanic_Survivors\\\\train.csv',quotechar='\"')\n",
    "#Replace NaN values with 0\n",
    "test_dataframe.fillna(float(0), inplace=True)\n",
    "train_dataframe.fillna(float(0), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex   \n",
       "0          892       3                              Kelly, Mr. James    male  \\\n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   0.0        Q  \n",
       "1  47.0      1      0   363272   7.0000   0.0        S  \n",
       "2  62.0      0      0   240276   9.6875   0.0        Q  \n",
       "3  27.0      0      0   315154   8.6625   0.0        S  \n",
       "4  22.0      1      1  3101298  12.2875   0.0        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1                                                  2       3     4    \n",
       "0      1  3                            Braund, Mr. Owen Harris    male  22.0  \\\n",
       "1      2  1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "2      3  3                             Heikkinen, Miss. Laina  female  26.0   \n",
       "3      4  1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "4      5  3                           Allen, Mr. William Henry    male  35.0   \n",
       "..   ... ..                                                ...     ...   ...   \n",
       "886  887  2                              Montvila, Rev. Juozas    male  27.0   \n",
       "887  888  1                       Graham, Miss. Margaret Edith  female  19.0   \n",
       "888  889  3           Johnston, Miss. Catherine Helen \"Carrie\"  female   0.0   \n",
       "889  890  1                              Behr, Mr. Karl Howell    male  26.0   \n",
       "890  891  3                                Dooley, Mr. Patrick    male  32.0   \n",
       "\n",
       "    5  6                 7        8     9  10  \n",
       "0    1  0         A/5 21171     7.25   0.0  S  \n",
       "1    1  0          PC 17599  71.2833   C85  C  \n",
       "2    0  0  STON/O2. 3101282    7.925   0.0  S  \n",
       "3    1  0            113803     53.1  C123  S  \n",
       "4    0  0            373450     8.05   0.0  S  \n",
       "..  .. ..               ...      ...   ... ..  \n",
       "886  0  0            211536     13.0   0.0  S  \n",
       "887  0  0            112053     30.0   B42  S  \n",
       "888  1  2        W./C. 6607    23.45   0.0  S  \n",
       "889  0  0            111369     30.0  C148  C  \n",
       "890  0  0            370376     7.75   0.0  Q  \n",
       "\n",
       "[891 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create train and test dataset\n",
    "test_dataset = pd.DataFrame.to_numpy(test_dataframe)\n",
    "train_dataset = pd.DataFrame.to_numpy(train_dataframe)\n",
    "\n",
    "#Split the training dataset to data and targets\n",
    "targets = train_dataset[:, 1]\n",
    "train_dataset = np.delete(train_dataset, 1, 1)\n",
    "\n",
    "pd.DataFrame(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "y = train_dataframe[\"Survived\"]\n",
    "\n",
    "features = [\"Pclass\", \"Sex\", \"SibSp\", \"Parch\",\"Fare\"]\n",
    "X = pd.get_dummies(train_dataframe[features], dummy_na=True)\n",
    "X_test = pd.get_dummies(test_dataframe[features], dummy_na=True)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n",
    "model.fit(X, y)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': test_dataframe.PassengerId, 'Survived': predictions})\n",
    "output.to_csv('submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding string values (Name, Ticket and Sex)\n",
    "- Depending on who you are, how well-known is your name or your family name, the chances of you surviving can be higher.\n",
    "- Furthermore, being in a group (ie. family) can increase your survival.\n",
    "- So we need to somehow categorize names of each individuals to better improve the model.\n",
    "\n",
    ">ps: i just want to try embedding strings ok..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Sex - Categorical Encoding\n",
    "- We need to transfer the words \"male\" and \"female\" to numeric representations for the AI model to work with.\n",
    "- For this, we use OneHotEncoder - which maps each unique label to an integer value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "#Insantiate the encoder\n",
    "sex_encoder = OrdinalEncoder()\n",
    "#Get the sex attribute column from train dataset\n",
    "sex_Col = train_dataset[:,3].reshape(-1,1)\n",
    "sex_Col\n",
    "#Fit and transform the data, then flatten the output since OrdinalEncoder outputs 2-D arrays\n",
    "enc_sex = sex_encoder.fit_transform(sex_Col).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3, 'Braund, Mr. Owen Harris', ..., 7.25, 0.0, 'S'],\n",
       "       [2, 1, 'Cumings, Mrs. John Bradley (Florence Briggs Thayer)', ...,\n",
       "        71.2833, 'C85', 'C'],\n",
       "       [3, 3, 'Heikkinen, Miss. Laina', ..., 7.925, 0.0, 'S'],\n",
       "       ...,\n",
       "       [889, 3, 'Johnston, Miss. Catherine Helen \"Carrie\"', ..., 23.45,\n",
       "        0.0, 'S'],\n",
       "       [890, 1, 'Behr, Mr. Karl Howell', ..., 30.0, 'C148', 'C'],\n",
       "       [891, 3, 'Dooley, Mr. Patrick', ..., 7.75, 0.0, 'Q']], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[:, 3] = enc_sex\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~### 2. Ticket - Tf/Idf encoder~~\n",
    "~~- Tickets are usually fairly unique to each other.~~\n",
    "~~- So, to save memory but still preserve some sense of relationship that the model can figure out, we use **Tf/Idf Encoder**.~~\n",
    "~~- As in, **Term Frequency** and **Inverse Document Frequency**.~~\n",
    "~~- The encoder works by mapping every unique word to a real value, the more the word occurs in the document, the higher its \"score\".~~\n",
    "~~- But it also minimizes words that are meaningless in terms of learning - like 'the','a',etc.~~\n",
    "\n",
    "### 2. Ticket - Hashing Vectorizer\n",
    "- We will hash all words into a hashing table, with corresponding hash values.\n",
    "- **Problem with TF/IDF**: The shape of the output vector between train_dataset and test_dataset can be different (because their vocabulary is different)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "#Insantiate the encoder/vectorizer\n",
    "#ticket_vectorizer = TfidfVectorizer(analyzer=\"word\")\n",
    "ticket_vectorizer = HashingVectorizer(n_features=2000)\n",
    "#Get the ticket attribute column from train dataset\n",
    "ticketCol = train_dataset[:, 7]\n",
    "#Fit the training data to the vectorizer\n",
    "ticket_vectorizer.fit(ticketCol)\n",
    "enc_ticket = ticket_vectorizer.transform(ticketCol)\n",
    "enc_ticket = enc_ticket.toarray()\n",
    "enc_ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate the new vectors to train dataset\n",
    "train_dataset = np.concatenate((train_dataset, enc_ticket), axis=1)\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insantiate the encoder/vectorizer\n",
    "#name_vectorizer = TfidfVectorizer(analyzer=\"word\")\n",
    "name_vectorizer = HashingVectorizer(n_features=2000)\n",
    "#Get the ticket attribute column from train dataset\n",
    "nameCol = train_dataset[:, 2]\n",
    "#Fit the training data to the vectorizer\n",
    "name_vectorizer.fit(nameCol)\n",
    "enc_name = name_vectorizer.transform(nameCol)\n",
    "enc_name = enc_name.toarray()\n",
    "enc_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate the new vectors to train dataset\n",
    "train_dataset = np.concatenate((train_dataset, enc_name), axis=1)\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insantiate the encoder\n",
    "emb_encoder = OrdinalEncoder()\n",
    "#Get the data\n",
    "emb_col = train_dataset[:, 10].reshape(-1 , 1).astype(str)\n",
    "enc_emb = emb_encoder.fit_transform(emb_col).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3, 'Braund, Mr. Owen Harris', ..., 7.25, 0.0, 3.0],\n",
       "       [2, 1, 'Cumings, Mrs. John Bradley (Florence Briggs Thayer)', ...,\n",
       "        71.2833, 'C85', 1.0],\n",
       "       [3, 3, 'Heikkinen, Miss. Laina', ..., 7.925, 0.0, 3.0],\n",
       "       ...,\n",
       "       [889, 3, 'Johnston, Miss. Catherine Helen \"Carrie\"', ..., 23.45,\n",
       "        0.0, 3.0],\n",
       "       [890, 1, 'Behr, Mr. Karl Howell', ..., 30.0, 'C148', 1.0],\n",
       "       [891, 3, 'Dooley, Mr. Patrick', ..., 7.75, 0.0, 2.0]], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[:,10] = enc_emb\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's put everything into a callable class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    def categoricalEncode(self, dataset, column):\n",
    "        encoder = OrdinalEncoder()\n",
    "        #Get the sex attribute column from train dataset\n",
    "        data = dataset[:, column].reshape(-1,1).astype(str)\n",
    "        #Fit and transform the data, then flatten the output since OrdinalEncoder outputs 2-D arrays\n",
    "        enc_data = encoder.fit_transform(data).flatten()\n",
    "        dataset[:, column] = enc_data\n",
    "        return dataset\n",
    "\n",
    "    def HashingEncode(self, dataset, column, n_features=2000):\n",
    "        #Insantiate the encoder/vectorizer\n",
    "        vectorizer = HashingVectorizer(n_features=n_features)\n",
    "        vectorizer = name_vectorizer if column == 2 else ticket_vectorizer\n",
    "        #Get the ticket attribute column from train dataset\n",
    "        data = dataset[:, column]\n",
    "        #Fit the training data to the vectorizer\n",
    "        #vectorizer.fit(data)\n",
    "        enc_data = vectorizer.transform(data)\n",
    "        enc_data = enc_data.toarray()\n",
    "        \n",
    "        dataset = np.concatenate((dataset, enc_data), axis=1)\n",
    "        return dataset\n",
    "    \n",
    "    def preprocess(self, dataset, categorical_columns = None, tf_idf_columns = None):\n",
    "        \n",
    "        #Categorical encoding\n",
    "        if categorical_columns == None:\n",
    "            #Sex\n",
    "            dataset = self.categoricalEncode(dataset, 3)\n",
    "            #Embarked\n",
    "            dataset = self.categoricalEncode(dataset, 10)\n",
    "        else:\n",
    "            for col in categorical_columns:\n",
    "                dataset = self.categoricalEncode(dataset, col)\n",
    "        \n",
    "        #Feature extraction (tf_idf) encoding\n",
    "        if tf_idf_columns == None:\n",
    "            #Name\n",
    "            dataset = self.HashingEncode(dataset, 2)\n",
    "            #Ticket\n",
    "            dataset = self.HashingEncode(dataset, 7) \n",
    "        else:\n",
    "            for col in tf_idf_columns:\n",
    "                dataset = self.HashingEncode(dataset, col)\n",
    "\n",
    "        return dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's call the processor class to preprocess our test_dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([892, 3, 'Kelly, Mr. James', 1.0, 34.5, 0, 0, '330911', 7.8292, 0.0,\n",
       "       1.0], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Preprocessor()\n",
    "\n",
    "test_dataset = processor.categoricalEncode(test_dataset, 3)\n",
    "\n",
    "test_dataset = processor.categoricalEncode(test_dataset, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                          Name   \n",
       "0            892       3                              Kelly, Mr. James  \\\n",
       "1            893       3              Wilkes, Mrs. James (Ellen Needs)   \n",
       "2            894       2                     Myles, Mr. Thomas Francis   \n",
       "3            895       3                              Wirz, Mr. Albert   \n",
       "4            896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
       "..           ...     ...                                           ...   \n",
       "413         1305       3                            Spector, Mr. Woolf   \n",
       "414         1306       1                  Oliva y Ocana, Dona. Fermina   \n",
       "415         1307       3                  Saether, Mr. Simon Sivertsen   \n",
       "416         1308       3                           Ware, Mr. Frederick   \n",
       "417         1309       3                      Peter, Master. Michael J   \n",
       "\n",
       "        Sex   Age  SibSp  Parch              Ticket      Fare Cabin Embarked  \n",
       "0      male  34.5      0      0              330911    7.8292   0.0        Q  \n",
       "1    female  47.0      1      0              363272    7.0000   0.0        S  \n",
       "2      male  62.0      0      0              240276    9.6875   0.0        Q  \n",
       "3      male  27.0      0      0              315154    8.6625   0.0        S  \n",
       "4    female  22.0      1      1             3101298   12.2875   0.0        S  \n",
       "..      ...   ...    ...    ...                 ...       ...   ...      ...  \n",
       "413    male   0.0      0      0           A.5. 3236    8.0500   0.0        S  \n",
       "414  female  39.0      0      0            PC 17758  108.9000  C105        C  \n",
       "415    male  38.5      0      0  SOTON/O.Q. 3101262    7.2500   0.0        S  \n",
       "416    male   0.0      0      0              359309    8.0500   0.0        S  \n",
       "417    male   0.0      1      1                2668   22.3583   0.0        C  \n",
       "\n",
       "[418 rows x 11 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_features = [0, 2, 7, 9] #Omit \"ID\", \"Cabin\", old \"Name\", old \"Ticket\" and \"Embarked\" feature\n",
    "\n",
    "train_dataset = np.delete(train_dataset, delete_features, axis=1)\n",
    "test_dataset = np.delete(test_dataset, delete_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert dtype to float64\n",
    "train_dataset = train_dataset.astype(np.float64)\n",
    "test_dataset = test_dataset.astype(np.float64)\n",
    "targets = targets.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.308642    0.64758706 23.799297    0.5230078   0.38159373 32.20421\n",
      "   2.5297413 ]]\n"
     ]
    }
   ],
   "source": [
    "#Layer to normalize training data\n",
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "\n",
    "#Adapt the normalizer to data\n",
    "normalizer.adapt(train_dataset)\n",
    "\n",
    "print(normalizer.mean.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = tf.keras.Sequential([\n",
    "                                    normalizer,\n",
    "                                    tf.keras.layers.Dense(len(train_dataset[0]), activation='relu'), #You should have an input layer with the size of the input vector\n",
    "                                    tf.keras.layers.Dense(1)],\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 78ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.28106833],\n",
       "       [ 1.1892489 ],\n",
       "       [-0.29475987],\n",
       "       [-0.18169472],\n",
       "       [ 0.6368168 ],\n",
       "       [ 0.8815734 ],\n",
       "       [ 0.5167075 ],\n",
       "       [-0.3050456 ],\n",
       "       [-0.15823054],\n",
       "       [ 1.1784658 ]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.predict(train_dataset[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "23/23 [==============================] - 1s 12ms/step - loss: 0.2682 - val_loss: 0.1459\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1613 - val_loss: 0.1370\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.1608 - val_loss: 0.1322\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1621 - val_loss: 0.1283\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1531 - val_loss: 0.1413\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1601 - val_loss: 0.1264\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.1541 - val_loss: 0.1397\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1569 - val_loss: 0.1306\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1528 - val_loss: 0.1311\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.1522 - val_loss: 0.1362\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.1544 - val_loss: 0.1267\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1535 - val_loss: 0.1696\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1744 - val_loss: 0.1434\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1616 - val_loss: 0.1356\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1608 - val_loss: 0.1376\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.1611 - val_loss: 0.1294\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.1695 - val_loss: 0.1381\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1647 - val_loss: 0.1764\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1687 - val_loss: 0.1525\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1629 - val_loss: 0.1384\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1545 - val_loss: 0.1354\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1573 - val_loss: 0.1423\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1564 - val_loss: 0.1414\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1659 - val_loss: 0.1324\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1591 - val_loss: 0.1484\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1720 - val_loss: 0.1559\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1766 - val_loss: 0.1680\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1620 - val_loss: 0.1285\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1588 - val_loss: 0.1297\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1536 - val_loss: 0.1382\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1629 - val_loss: 0.1439\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1644 - val_loss: 0.1306\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1503 - val_loss: 0.1311\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1594 - val_loss: 0.1341\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1605 - val_loss: 0.1374\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1549 - val_loss: 0.1258\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1535 - val_loss: 0.1336\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1512 - val_loss: 0.1373\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1520 - val_loss: 0.1342\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1568 - val_loss: 0.1318\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.1562 - val_loss: 0.1330\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1523 - val_loss: 0.1451\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1645 - val_loss: 0.1322\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1586 - val_loss: 0.1350\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1594 - val_loss: 0.1360\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1581 - val_loss: 0.1990\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1820 - val_loss: 0.1709\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.1677 - val_loss: 0.1392\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1554 - val_loss: 0.1749\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.1666 - val_loss: 0.1311\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x214121a9890>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "    loss=tf.keras.losses.MeanSquaredError()\n",
    ")\n",
    "\n",
    "linear_model.fit(\n",
    "    train_dataset,\n",
    "    targets,\n",
    "    epochs=50,\n",
    "    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset[0]) == len(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "..  ..\n",
       "413  0\n",
       "414  1\n",
       "415  0\n",
       "416  0\n",
       "417  0\n",
       "\n",
       "[418 rows x 1 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict test dataset\n",
    "predictions = linear_model.predict(test_dataset)\n",
    "\n",
    "#Some adjustments so there'd be no problem submitting\n",
    "for member in predictions:\n",
    "    if member[0] > 0.5:\n",
    "        member[0] = 1\n",
    "    else:\n",
    "        member[0] = 0\n",
    "\n",
    "predictions = predictions.astype(np.int32)\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "output = pd.DataFrame({'PassengerId': test_dataframe.PassengerId, 'Survived': predictions[0]})\n",
    "output.to_csv('submission.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
